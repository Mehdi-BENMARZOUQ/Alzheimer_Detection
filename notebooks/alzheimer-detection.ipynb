{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alzheimer Detection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T23:19:04.512441Z",
     "iopub.status.busy": "2024-02-17T23:19:04.512047Z",
     "iopub.status.idle": "2024-02-17T23:19:19.965354Z",
     "shell.execute_reply": "2024-02-17T23:19:19.963977Z",
     "shell.execute_reply.started": "2024-02-17T23:19:04.512409Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-04-30T08:54:43.457178Z",
     "start_time": "2025-04-30T08:54:36.120856Z"
    }
   },
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import itertools\n",
    "import torch\n",
    "%pip install efficientnet_pytorch\n",
    "%pip install timm\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet_pytorch in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from efficientnet_pytorch) (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from torch->efficientnet_pytorch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from torch->efficientnet_pytorch) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from torch->efficientnet_pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from torch->efficientnet_pytorch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from torch->efficientnet_pytorch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from torch->efficientnet_pytorch) (79.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from torch->efficientnet_pytorch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from sympy==1.13.1->torch->efficientnet_pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from jinja2->torch->efficientnet_pytorch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: timm in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (1.0.15)\n",
      "Requirement already satisfied: torch in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from timm) (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from timm) (0.21.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from timm) (0.20.3)\n",
      "Requirement already satisfied: safetensors in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from huggingface_hub->timm) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from huggingface_hub->timm) (2025.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from huggingface_hub->timm) (4.13.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from huggingface_hub->timm) (24.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from torch->timm) (79.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from torchvision->timm) (2.2.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from torchvision->timm) (11.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\downloads\\alzheimer_detection-main\\alzheimer_detection-main\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T23:28:30.353785Z",
     "iopub.status.busy": "2024-02-17T23:28:30.353076Z",
     "iopub.status.idle": "2024-02-17T23:28:31.221814Z",
     "shell.execute_reply": "2024-02-17T23:28:31.220844Z",
     "shell.execute_reply.started": "2024-02-17T23:28:30.353750Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-04-30T08:56:10.023484Z",
     "start_time": "2025-04-30T08:56:09.951966Z"
    }
   },
   "source": [
    "# Define the directory where the data is stored\n",
    "# Replace with the path to your dataset\n",
    "data_dir = '/train/Mild_Impairment'\n",
    "\n",
    "# Define transforms for the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the dataset with ImageFolder\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "#with wandb.init(project='wound-detection'):\n",
    "# Split the dataset into train and validation sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% of dataset\n",
    "val_size = len(dataset) - train_size  # 20% of dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: '/train/Mild_Impairment'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 17\u001B[0m\n\u001B[0;32m      6\u001B[0m transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[0;32m      7\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mResize((\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m)),\n\u001B[0;32m      8\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mToTensor(),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     13\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mNormalize([\u001B[38;5;241m0.485\u001B[39m, \u001B[38;5;241m0.456\u001B[39m, \u001B[38;5;241m0.406\u001B[39m], [\u001B[38;5;241m0.229\u001B[39m, \u001B[38;5;241m0.224\u001B[39m, \u001B[38;5;241m0.225\u001B[39m])\n\u001B[0;32m     14\u001B[0m ])\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Load the dataset with ImageFolder\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mImageFolder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m#with wandb.init(project='wound-detection'):\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# Split the dataset into train and validation sets\u001B[39;00m\n\u001B[0;32m     21\u001B[0m train_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m0.8\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(dataset))  \u001B[38;5;66;03m# 80% of dataset\u001B[39;00m\n",
      "File \u001B[1;32m~\\Downloads\\Alzheimer_Detection-main\\Alzheimer_Detection-main\\.venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001B[0m, in \u001B[0;36mImageFolder.__init__\u001B[1;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001B[0m\n\u001B[0;32m    319\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    321\u001B[0m     root: Union[\u001B[38;5;28mstr\u001B[39m, Path],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    326\u001B[0m     allow_empty: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    327\u001B[0m ):\n\u001B[1;32m--> 328\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    329\u001B[0m \u001B[43m        \u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    330\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    331\u001B[0m \u001B[43m        \u001B[49m\u001B[43mIMG_EXTENSIONS\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    332\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_transform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_transform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    334\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_valid_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    335\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_empty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_empty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    337\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimgs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples\n",
      "File \u001B[1;32m~\\Downloads\\Alzheimer_Detection-main\\Alzheimer_Detection-main\\.venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001B[0m, in \u001B[0;36mDatasetFolder.__init__\u001B[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    140\u001B[0m     root: Union[\u001B[38;5;28mstr\u001B[39m, Path],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    146\u001B[0m     allow_empty: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    147\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(root, transform\u001B[38;5;241m=\u001B[39mtransform, target_transform\u001B[38;5;241m=\u001B[39mtarget_transform)\n\u001B[1;32m--> 149\u001B[0m     classes, class_to_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m     samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_dataset(\n\u001B[0;32m    151\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot,\n\u001B[0;32m    152\u001B[0m         class_to_idx\u001B[38;5;241m=\u001B[39mclass_to_idx,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    155\u001B[0m         allow_empty\u001B[38;5;241m=\u001B[39mallow_empty,\n\u001B[0;32m    156\u001B[0m     )\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader \u001B[38;5;241m=\u001B[39m loader\n",
      "File \u001B[1;32m~\\Downloads\\Alzheimer_Detection-main\\Alzheimer_Detection-main\\.venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001B[0m, in \u001B[0;36mDatasetFolder.find_classes\u001B[1;34m(self, directory)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfind_classes\u001B[39m(\u001B[38;5;28mself\u001B[39m, directory: Union[\u001B[38;5;28mstr\u001B[39m, Path]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[\u001B[38;5;28mstr\u001B[39m], Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m]]:\n\u001B[0;32m    208\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001B[39;00m\n\u001B[0;32m    209\u001B[0m \n\u001B[0;32m    210\u001B[0m \u001B[38;5;124;03m        directory/\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001B[39;00m\n\u001B[0;32m    233\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfind_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\Alzheimer_Detection-main\\Alzheimer_Detection-main\\.venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:41\u001B[0m, in \u001B[0;36mfind_classes\u001B[1;34m(directory)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfind_classes\u001B[39m(directory: Union[\u001B[38;5;28mstr\u001B[39m, Path]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[\u001B[38;5;28mstr\u001B[39m], Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m]]:\n\u001B[0;32m     37\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \n\u001B[0;32m     39\u001B[0m \u001B[38;5;124;03m    See :class:`DatasetFolder` for details.\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 41\u001B[0m     classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(entry\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m entry \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscandir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m entry\u001B[38;5;241m.\u001B[39mis_dir())\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m classes:\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find any class folder in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdirectory\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: '/train/Mild_Impairment'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean model: CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T23:20:24.587515Z",
     "iopub.status.busy": "2024-02-17T23:20:24.586834Z",
     "iopub.status.idle": "2024-02-17T23:20:25.141577Z",
     "shell.execute_reply": "2024-02-17T23:20:25.140784Z",
     "shell.execute_reply.started": "2024-02-17T23:20:24.587486Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-04-30T08:58:18.614743Z",
     "start_time": "2025-04-30T08:58:09.205710Z"
    }
   },
   "source": [
    "# # Load a pre-trained model (e.g., ResNet18) and modify it for our task\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all the layers in the pretrained model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final layer with a new one that matches our number of classes (4 classes in our case)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4) \n",
    "\n",
    "# Move the model to the GPU if available\n",
    "model = model.to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Downloads\\Alzheimer_Detection-main\\Alzheimer_Detection-main\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asus\\Downloads\\Alzheimer_Detection-main\\Alzheimer_Detection-main\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\asus/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:08<00:00, 12.4MB/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T23:20:32.925077Z",
     "iopub.status.busy": "2024-02-17T23:20:32.923850Z",
     "iopub.status.idle": "2024-02-17T23:20:32.929890Z",
     "shell.execute_reply": "2024-02-17T23:20:32.928970Z",
     "shell.execute_reply.started": "2024-02-17T23:20:32.925040Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-04-30T08:58:27.980854Z",
     "start_time": "2025-04-30T08:58:27.974591Z"
    }
   },
   "source": [
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer, only optimizing the parameters of the final layer\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T23:20:36.107078Z",
     "iopub.status.busy": "2024-02-17T23:20:36.106392Z",
     "iopub.status.idle": "2024-02-17T23:27:27.614093Z",
     "shell.execute_reply": "2024-02-17T23:27:27.613105Z",
     "shell.execute_reply.started": "2024-02-17T23:20:36.107050Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-04-30T08:58:30.325315Z",
     "start_time": "2025-04-30T08:58:30.284325Z"
    }
   },
   "source": [
    "# Number of epochs to train for\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in trainloader:\n",
    "        # Move the input and label tensors to the correct device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n",
    "    \n",
    "    # Validation loss\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Validation Loss: {val_loss / len(valloader)}, Accuracy: {100 * correct / total}%')\n",
    "torch.save(model.state_dict(), '/kaggle/working/alzheimer_cnn_model.pth')\n",
    "    "
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()  \u001B[38;5;66;03m# Set the model to training mode\u001B[39;00m\n\u001B[0;32m      6\u001B[0m running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtrainloader\u001B[49m:\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;66;03m# Move the input and label tensors to the correct device\u001B[39;00m\n\u001B[0;32m     10\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;66;03m# Zero the parameter gradients\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet for improved performance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T23:27:36.543735Z",
     "iopub.status.busy": "2024-02-17T23:27:36.543340Z",
     "iopub.status.idle": "2024-02-17T23:27:37.400657Z",
     "shell.execute_reply": "2024-02-17T23:27:37.399761Z",
     "shell.execute_reply.started": "2024-02-17T23:27:36.543705Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-04-30T08:58:37.149242Z",
     "start_time": "2025-04-30T08:58:36.976078Z"
    }
   },
   "source": [
    "efficientnet_model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=4)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "efficientnet_model = efficientnet_model.to(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify optimizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T23:28:41.708328Z",
     "iopub.status.busy": "2024-02-17T23:28:41.707655Z",
     "iopub.status.idle": "2024-02-17T23:28:41.713988Z",
     "shell.execute_reply": "2024-02-17T23:28:41.713055Z",
     "shell.execute_reply.started": "2024-02-17T23:28:41.708295Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-04-30T08:58:39.303512Z",
     "start_time": "2025-04-30T08:58:39.296041Z"
    }
   },
   "source": [
    "optimizer = optim.Adam(efficientnet_model.parameters(), lr=0.001)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T23:28:44.927992Z",
     "iopub.status.busy": "2024-02-17T23:28:44.927168Z",
     "iopub.status.idle": "2024-02-17T23:37:16.580237Z",
     "shell.execute_reply": "2024-02-17T23:37:16.579289Z",
     "shell.execute_reply.started": "2024-02-17T23:28:44.927958Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-04-30T08:58:40.856468Z",
     "start_time": "2025-04-30T08:58:40.816476Z"
    }
   },
   "source": [
    "# Number of epochs to train for\n",
    "num_epochs = 10\n",
    "\n",
    "# train efficientnet model\n",
    "for epoch in range(num_epochs):\n",
    "    efficientnet_model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in trainloader:\n",
    "        # Move the input and label tensors to the correct device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = efficientnet_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n",
    "    \n",
    "    # Validation loss\n",
    "    efficientnet_model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = efficientnet_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Validation Loss: {val_loss / len(valloader)}, Accuracy: {100 * correct / total}%')\n",
    "\n",
    "# Save the model\n",
    "    \n",
    "torch.save(efficientnet_model.state_dict(), '/kaggle/working/alzheimer_efficientnet_model.pth')\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m efficientnet_model\u001B[38;5;241m.\u001B[39mtrain()  \u001B[38;5;66;03m# Set the model to training mode\u001B[39;00m\n\u001B[0;32m      7\u001B[0m running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtrainloader\u001B[49m:\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m# Move the input and label tensors to the correct device\u001B[39;00m\n\u001B[0;32m     11\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;66;03m# Zero the parameter gradients\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Transformer for improved performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T23:42:07.476557Z",
     "iopub.status.busy": "2024-02-17T23:42:07.476144Z",
     "iopub.status.idle": "2024-02-17T23:42:14.203617Z",
     "shell.execute_reply": "2024-02-17T23:42:14.202788Z",
     "shell.execute_reply.started": "2024-02-17T23:42:07.476522Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/deit/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:63: UserWarning: Overwriting deit_tiny_patch16_224 in registry with models.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_tiny_patch16_224(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:78: UserWarning: Overwriting deit_small_patch16_224 in registry with models.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_small_patch16_224(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:93: UserWarning: Overwriting deit_base_patch16_224 in registry with models.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_base_patch16_224(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:108: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with models.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:123: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with models.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_small_distilled_patch16_224(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:138: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with models.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_base_distilled_patch16_224(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:153: UserWarning: Overwriting deit_base_patch16_384 in registry with models.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_base_patch16_384(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:168: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with models.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_base_distilled_patch16_384(pretrained=False, **kwargs):\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\" to /root/.cache/torch/hub/checkpoints/deit_base_patch16_224-b5f2ef4d.pth\n",
      "100%|██████████| 330M/330M [00:02<00:00, 152MB/s]  \n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained Vision Transformer model\n",
    "vit_model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "vit_model = vit_model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T23:42:42.027057Z",
     "iopub.status.busy": "2024-02-17T23:42:42.026716Z",
     "iopub.status.idle": "2024-02-17T23:42:42.033454Z",
     "shell.execute_reply": "2024-02-17T23:42:42.032563Z",
     "shell.execute_reply.started": "2024-02-17T23:42:42.027031Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the optimizer, only optimizing the parameters of the final layer\n",
    "optimizer = optim.Adam(vit_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T23:42:44.773964Z",
     "iopub.status.busy": "2024-02-17T23:42:44.773620Z",
     "iopub.status.idle": "2024-02-18T00:04:04.352295Z",
     "shell.execute_reply": "2024-02-18T00:04:04.351154Z",
     "shell.execute_reply.started": "2024-02-17T23:42:44.773939Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1634845238178968\n",
      "Validation Loss: 1.0732713043689728, Accuracy: 32.1875%\n",
      "Epoch 2, Loss: 1.0529922910034657\n",
      "Validation Loss: 1.0259643480181695, Accuracy: 53.359375%\n",
      "Epoch 3, Loss: 1.0125707723200321\n",
      "Validation Loss: 0.8805326148867607, Accuracy: 56.25%\n",
      "Epoch 4, Loss: 1.0047540474683045\n",
      "Validation Loss: 0.9534257456660271, Accuracy: 53.59375%\n",
      "Epoch 5, Loss: 0.9667909078299999\n",
      "Validation Loss: 0.8876874297857285, Accuracy: 55.703125%\n",
      "Epoch 6, Loss: 0.9608717679977417\n",
      "Validation Loss: 0.9172666013240814, Accuracy: 58.515625%\n",
      "Epoch 7, Loss: 0.9600563608109951\n",
      "Validation Loss: 0.8975788906216622, Accuracy: 55.78125%\n",
      "Epoch 8, Loss: 0.9425622124224902\n",
      "Validation Loss: 0.9373615071177482, Accuracy: 54.921875%\n",
      "Epoch 9, Loss: 0.9452154040336609\n",
      "Validation Loss: 0.9440957054495811, Accuracy: 54.296875%\n",
      "Epoch 10, Loss: 0.9265390537679196\n",
      "Validation Loss: 0.8854614362120629, Accuracy: 56.953125%\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs to train for\n",
    "num_epochs = 10\n",
    "\n",
    "# train Vision Transformer model\n",
    "for epoch in range(num_epochs):\n",
    "    vit_model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # torch.uint8 is supported on the CPU only, so we need to move the input and label tensors to the correct device\n",
    "    for inputs, labels in trainloader:\n",
    "        # Move the input and label tensors to the correct device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = vit_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n",
    "    \n",
    "    # Validation loss\n",
    "    vit_model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = vit_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Validation Loss: {val_loss / len(valloader)}, Accuracy: {100 * correct / total}%')\n",
    "# Save the model\n",
    "torch.save(vit_model.state_dict(), '/kaggle/working/alzheimer_vit_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T16:32:55.752068Z",
     "iopub.status.busy": "2024-02-18T16:32:55.751240Z",
     "iopub.status.idle": "2024-02-18T16:32:56.102803Z",
     "shell.execute_reply": "2024-02-18T16:32:56.101693Z",
     "shell.execute_reply.started": "2024-02-18T16:32:55.752025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_loss(train_losses, val_losses, title='Loss Plot'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device, criterion):\n",
    "    model.eval()  # Set model to evaluate mode\n",
    "    val_losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_losses.append(loss.item())\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
    "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Plot loss and confusion matrix\n",
    "    plot_loss([], val_losses, title='Validation Loss')  # Pass training losses if available\n",
    "    plot_confusion_matrix(cm, classes=['Mild_Demented', 'Moderate_Demented', 'Non_Demented', 'Very_Mild_Demented'], title='Confusion Matrix')\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating ResNet\n",
    "evaluate_model(model, valloader, device, criterion)\n",
    "\n",
    "# Evaluating  EfficientNet Model\n",
    "evaluate_model(efficientnet_model, valloader, device, criterion)\n",
    "\n",
    "# Evaluating Vision Transformer\n",
    "evaluate_model(vit_model, valloader, device, criterion)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2029496,
     "sourceId": 3364939,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
